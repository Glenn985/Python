import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('linea_regression_dataset.txt', sep='\s+')

df = df.dropna()

plt.scatter(df.X,df.Y)


def loss_function(m,b,points):
    total_error = 0
    for i in range(len(points)):
        x = points.iloc[i].X
        y = points.iloc[i].X
        total_error += (y-(m*x + b))**2
    return total_error/float(len(points))

def gradient_descent(m_now,b_now,points,L):
    m_gradient = 0
    b_gradient = 0

    n = len(points)

    for i in range(n):
        x = points.iloc[i].X
        y = points.iloc[i].Y

        m_gradient += -(2/n)*x*(y-(m_now * x + b_now))
        b_gradient += -(2/n)*(y-(m_now * x + b_now))

    m = m_now - m_gradient*L
    b = b_now - b_gradient*L
    return m,b

m = 0
b = 0
L = 0.0001
epochs = 1000

for i in range(epochs):
    if i%50 == 0:
        print(f"Epoch:{i}")
    m,b = gradient_descent(m,b,df,L)

plt.scatter(df.X,df.Y)
plt.plot(list(range(20,80)),[m*x+b for x in range(20,80)],color="red")

x_new = 10
y_pred = m * x_new + b
print("Predicted y for x_new =", x_new, ":", y_pred)
        

plt.show()


x_new = 58
y_pred = m * x_new + b
print("Predicted y for x_new =", x_new, ":", y_pred)
        

